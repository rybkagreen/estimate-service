#!/usr/bin/env node

/**
 * Ğ¢ĞµÑÑ‚ Ğ´Ğ»Ñ Hugging Face API ĞºĞ°Ğº Ğ°Ğ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ° DeepSeek
 * Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Hugging Face Inference API
 */

import dotenv from 'dotenv';
import path from 'path';

// Load environment variables
dotenv.config({ path: path.resolve('../.env') });

const hfApiKey = process.env.HUGGINGFACE_API_KEY || 'your-huggingface-api-key';
const baseUrl = 'https://api-inference.huggingface.co/models';

console.log('ğŸ§ª Testing Hugging Face API as DeepSeek alternative...\n');
console.log(`ğŸ”— Base URL: ${baseUrl}`);
console.log(`ğŸ”‘ HF API Key: ${hfApiKey.slice(0, 8)}...${hfApiKey.slice(-4)}`);

// Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ¿Ğ¾Ğ¿ÑƒĞ»ÑÑ€Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ½Ğ° Hugging Face Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
const modelsToTest = [
  'microsoft/DialoGPT-medium',
  'facebook/blenderbot-400M-distill',
  'microsoft/DialoGPT-small',
  'deepseek-ai/deepseek-coder-6.7b-instruct', // Ğ•ÑĞ»Ğ¸ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ° Ğ½Ğ° HF
  'deepseek-ai/deepseek-llm-7b-chat' // Ğ•ÑĞ»Ğ¸ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ° Ğ½Ğ° HF
];

async function testHuggingFaceModel(modelName) {
  try {
    console.log(`\nğŸ” Testing model: ${modelName}`);

    const response = await fetch(`${baseUrl}/${modelName}`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${hfApiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        inputs: 'Hello! Please respond with "API working" if you can hear me.',
        parameters: {
          max_length: 50,
          temperature: 0.1
        }
      })
    });

    console.log(`Status: ${response.status} ${response.statusText}`);

    if (!response.ok) {
      const errorText = await response.text();
      console.log(`âŒ ${modelName}: ERROR - ${errorText}`);
      return false;
    }

    const result = await response.json();

    if (Array.isArray(result) && result[0]?.generated_text) {
      console.log(`âœ… ${modelName}: SUCCESS`);
      console.log(`   Response: "${result[0].generated_text}"`);
      return true;
    } else {
      console.log(`âš ï¸ ${modelName}: Unexpected response format:`, result);
      return false;
    }

  } catch (error) {
    console.log(`âŒ ${modelName}: Network error - ${error.message}`);
    return false;
  }
}

// Ğ¢ĞµÑÑ‚ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚Ğ¸ API
console.log('\nğŸ“‹ Testing Hugging Face API access...');

let successCount = 0;
for (const model of modelsToTest) {
  const success = await testHuggingFaceModel(model);
  if (success) successCount++;

  // ĞŸĞ°ÑƒĞ·Ğ° Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°Ğ¼Ğ¸, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ½Ğµ Ğ¿Ñ€ĞµĞ²Ñ‹ÑĞ¸Ñ‚ÑŒ rate limit
  await new Promise(resolve => setTimeout(resolve, 1000));
}

console.log(`\nğŸ Test completed!`);
console.log(`âœ… Successful models: ${successCount}/${modelsToTest.length}`);

if (successCount > 0) {
  console.log('\nğŸ’¡ Hugging Face API is working! You could use it as an alternative to DeepSeek.');
  console.log('ğŸ“ To integrate with the MCP server, you would need to:');
  console.log('1. Update the DeepSeekService to use Hugging Face API format');
  console.log('2. Modify the request/response handling for HF models');
  console.log('3. Update environment variables for HF configuration');
} else {
  console.log('\nâŒ No models worked. This could be due to:');
  console.log('1. Invalid API key');
  console.log('2. Models not available or loading');
  console.log('3. Rate limiting');
}

console.log('\nğŸ¯ Recommendation: Get a proper DeepSeek API key from platform.deepseek.com');
console.log('   DeepSeek offers better performance and is specifically designed for this use case.');
